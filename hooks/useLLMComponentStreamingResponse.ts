import { transform } from "@babel/standalone";
import * as React from "react";
import { useCallback, useEffect, useState } from "react";
import depres from "depres";

const articleCache: { [key: string]: any } = {};

const useArticle = (id: string) => {
  const [data, setData] = useState<any[]>([]);
  useEffect(() => {
    if (articleCache[id]) {
      setData(articleCache[id]);
      return;
    }
    fetch(`/api/xkcd/article/${id}`).then((res) =>
      res.json().then((data) => {
        articleCache[id] = data;
        setData(data);
      }),
    );
  }, [id]);
  return data;
};

const useAllArticles = () => {
  const [data, setData] = useState<any[]>([]);
  useEffect(() => {
    fetch(`/api/xkcd/article?startId=1&endId=10`).then((res) =>
      res.json().then((data) => {
        setData(data);
      }),
    );
  }, []);
  return data;
};

interface Snippet {
  code: string;
  transpiled: string;
  dependencies: string[];
}

const staticDependencies: { [key: string]: any } = {
  react: React,
  useArticle: useArticle,
  useAllArticles: useAllArticles,
};

// Runs the actual code. This can easily crash if the code generated is incorrect or if it imports some external module, etc. With more time a crash should probably cause it to generate a fresh component
function instantiateSnippet(transpiled: string) {
  const wrappedJsCode = `return function({ ${Object.keys(
    staticDependencies,
  ).join(
    ", ",
  )},  module, require }) { const f = () => { ${transpiled} }; return f(); }`;
  return new Function("React", wrappedJsCode)();
}

export default function useLLMComponentStreamingResponse() {
  const [data, setData] = useState<string>("");
  // The state variable keeps track of when to query or rerender, this is a bit ugly. Possibly could've been made simpler with a state machine
  const [state, setState] = useState<string>("uninitialized");
  const [query, setQuery] = useState<string>("");
  // When a component has been generated by the llm then it first gets put into `pendingSnippets`, since we might not have all the dependencies rendered yet
  const [pendingSnippets, setPendingSnippets] = useState<Snippet[]>([]);
  // Finished/rendered components go herea
  const [components, setComponents] = useState<{ [key: string]: any }>({});

  const completion = useCallback(async (query: string) => {
    setQuery(query);
    setState("fetch");
  }, []);

  // Fetches a dependency for rendering, so when require("FILE") is called, this method is invoked
  const getDependency = useCallback(
    (path: string) => {
      const p = path.startsWith("./") ? path.slice(2) : path;
      if (p in staticDependencies) {
        return staticDependencies[p];
      }
      return components[p]?.component;
    },
    [components],
  );

  useEffect(() => {
    // When a component is updated we have to rerender that part of the tree/dom, unfortunately I didn't have time to make something smarter. So instead we resolve the dependency graph and then we rerender all components
    if (
      !pendingSnippets.length &&
      state === "rerender" &&
      Object.keys(components).length
    ) {
      // Resolve dependency graph
      const map: { [key: string]: string[] } = {};
      for (const [key, value] of Object.entries(components)) {
        map[key] = value.dependencies.filter(
          (dep: string) => !(dep in staticDependencies),
        );
      }
      var resolvedMap = depres.resolveMap(map);

      // Iterate over each component one by one and rerender it
      const newState = { ...components };
      for (let i = 0; i < resolvedMap.resolved.length; ++i) {
        const key = resolvedMap.resolved[i];
        const value = newState[key];
        const m: any = { exports: {} };
        instantiateSnippet(value.transpiled)({
          ...staticDependencies,
          module: m,
          // We inject another require function so we actually use the newly rerender components, otherwise we could have used `getDependency`
          require: (path: string) => {
            const p = path.startsWith("./") ? path.slice(2) : path;
            if (p in staticDependencies) {
              return staticDependencies[p];
            }
            return newState[p]?.component;
          },
        });
        const e = m.exports.default ?? m.exports;
        newState[key] = {
          ...value,
          component: e,
        };
      }
      setComponents(newState);
      setState("idle");
    }
  }, [pendingSnippets, state, getDependency]);

  useEffect(() => {
    // This hook traverses all unrendered components and check if all their dependencies are resolved, if so then we render that component
    const toRemove: number[] = [];
    const toAdd: { [key: string]: any } = {};
    pendingSnippets.forEach((snippet, i) => {
      // Check if all dependencies can be resolved
      const allDependenciesResolved = snippet.dependencies.every((dep) =>
        getDependency(dep),
      );
      if (allDependenciesResolved) {
        const m: any = { exports: {} };
        instantiateSnippet(snippet.transpiled)({
          ...staticDependencies,
          module: m,
          require: getDependency,
        });
        const e = m.exports.default ?? m.exports;
        toRemove.push(i);
        toAdd[e.name] = {
          component: e,
          dependencies: snippet.dependencies,
          transpiled: snippet.transpiled,
          code: snippet.code,
        };
      }
    });
    if (Object.keys(toAdd).length) {
      setComponents((prev) => ({ ...prev, ...toAdd }));
    }
    if (toRemove.length) {
      setPendingSnippets((prev) =>
        prev.filter((_, i) => !toRemove.includes(i)),
      );
    }
  }, [pendingSnippets, components, getDependency]);

  useEffect(() => {
    // This hook queries the actual LLM and listens for new components and the completion delta
    async function fetchData(eventSource: EventSource) {
      // This event fires on each streaming response
      eventSource.addEventListener("openai-chat-completion", (event) => {
        const newData = decodeURI(event.data);
        setData((prevData: string) => prevData + newData);
      });
      // This event fires when the LLM has generated a snippet containing a full react component
      eventSource.addEventListener("component", (event) => {
        const m: any = { exports: {} };
        const dependencies: string[] = [];
        const raw = decodeURI(event.data);
        // Transpile and convert ESM modules to CJS, so it can be injected in a browser env
        const data = transform(raw, {
          presets: ["react"],
        }).code as string;

        // We inject this require function so we can detect all the dependencies of the component
        const r = (path: string) => {
          const p = path.startsWith("./") ? path.slice(2) : path;
          dependencies.push(p);
          return getDependency(p);
        };
        try {
          // We initialize the component, but this is only so we can detect the dependencies
          instantiateSnippet(data)({
            ...staticDependencies,
            module: m,
            require: r,
          });
        } finally {
          setPendingSnippets((prev) => [
            ...prev,
            {
              code: raw,
              transpiled: data,
              dependencies,
            },
          ]);
        }
      });
      // A bit confusing, but this fires when the response is done
      eventSource.addEventListener("error", () => {
        setState("rerender");
        eventSource.close();
      });
      return eventSource;
    }
    if (query && state === "fetch") {
      const es = new EventSource(
        `/api/openai-chat-completion?message=${encodeURIComponent(query)}`,
      );
      fetchData(es);
      setState("loading");
    }
  }, [state, query, getDependency]);
  return {
    data,
    components,
    RootComponent: components.Root?.component,
    completion,
    state,
  };
}
